@Electronic{york,
  author       = {York St John University,},
  howpublished = {2021},
  language     = {English},
  organization = {York St John University,},
  title        = {Examples of research proposals },
  url          = {https://www.yorksj.ac.uk/study/research/apply/examples-of-research-proposals/},
  year         = {2021},
}

@article{wong2016write,
  title={How to write a research proposal},
  author={Wong, Paul TP and Psych, C},
  journal={Langley: Trinity Western University Langley. Retrieved},
  volume={26},
  year={2016}
}
@article{sudheesh2016write,
  title={How to write a research proposal?},
  author={Sudheesh, K and Duggappa, Devika Rani and Nethra, SS},
  journal={Indian journal of anaesthesia},
  volume={60},
  number={9},
  pages={631},
  year={2016},                  
  publisher={Wolters Kluwer--Medknow Publications}
}

@article{nte2006research,
  title={Research proposal writing: Breaking the myth},
  author={Nte, AR and Awi, DD},
  journal={Nigerian Journal of Medicine},
  volume={15},
  number={4},
  pages={373--381},
  year={2006}
}
@article{iqbal2007learning,
  title={Learning from a Doctoral Research Project: Structure and Content of a Research Proposal.},
  author={Iqbal, Javed},
  journal={Electronic Journal of Business Research Methods},
  volume={5},
  number={1},
  year={2007}
}
@article{QIU2022108362,
title = {A deep reinforcement learning-based approach for the home delivery and installation routing problem},
journal = {International Journal of Production Economics},
volume = {244},
pages = {108362},
year = {2022},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2021.108362},
url = {https://www.sciencedirect.com/science/article/pii/S0925527321003388},
author = {Huaxin Qiu and Sutong Wang and Yunqiang Yin and Dujuan Wang and Yanzhang Wang},
keywords = {Delivery and installation routing problem, Deep reinforcement learning, Encoder-decoder model, Attention mechanism},
abstract = {This paper investigates a home delivery and installation routing problem with synchronization constraints stemming from a home industry company in China who provides the last-mile delivery of home decoration and furniture. The company first arranges for products to be delivered from door to door, and later the technicians come to perform the installation service for the customers. The products for each customer must be firstly delivered to the customer by a vehicle and then installed by technicians. The objective is to identify the optimal delivery routes of the vehicles and optimal service routes of the technicians so as to minimize the total travel distance of the delivery and service routes. A deep reinforcement learning method in an Encoder-Decoder fashion with multi-head attention mechanism and beam search strategy is developed to solve the problem. To evaluate the designed method, extensive numerical experiments based on real service networks provided by the company are conducted. The results show that the proposed method can effectively solve the problem, which outperforms some classical strategies, and some meaningful management implications are provided.}
}
@article{HUANG2022108353,
title = {Learning to select cuts for efficient mixed-integer programming},
journal = {Pattern Recognition},
volume = {123},
pages = {108353},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108353},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321005331},
author = {Zeren Huang and Kerong Wang and Furui Liu and Hui-Ling Zhen and Weinan Zhang and Mingxuan Yuan and Jianye Hao and Yong Yu and Jun Wang},
keywords = {Mixed-Integer programming, Cutting plane, Multiple instance learning, Generalization ability},
abstract = {Cutting plane methods play a significant role in modern solvers for tackling mixed-integer programming (MIP) problems. Proper selection of cuts would remove infeasible solutions in the early stage, thus largely reducing the computational burden without hurting the solution accuracy. However, the major cut selection approaches heavily rely on heuristics, which strongly depend on the specific problem at hand and thus limit their generalization capability. In this paper, we propose a data-driven and generalizable cut selection approach, named Cut Ranking, in the settings of multiple instance learning. To measure the quality of the candidate cuts, a scoring function, which takes the instance-specific cut features as inputs, is trained and applied in cut ranking and selection. In order to evaluate our method, we conduct extensive experiments on both synthetic datasets and real-world datasets. Compared with commonly used heuristics for cut selection, the learning-based policy has shown to be more effective, and is capable of generalizing over multiple problems with different properties. Cut Ranking has been deployed in an industrial solver for large-scale MIPs. In the online A/B testing of the product planning problems with more than 107 variables and constraints daily, Cut Ranking has achieved the average speedup ratio of 12.42% over the production solver without any accuracy loss of solution.}
}
@article{CHEN2022939,
author = {Xinwei Chen and Marlin W. Ulmer and Barrett W. Thomas},
title = {Deep Q-learning for same-day delivery with vehicles and drones},
journal = {European Journal of Operational Research},
volume = {298},
number = {3},
pages = {939-952},
year = {2022},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2021.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0377221721005361},
keywords = {Transportation, Same-day delivery, Reinforcement learning, Dynamic vehicle routing},
abstract = {In this paper, we consider same-day delivery with vehicles and drones. Customers make delivery requests over the course of the day, and the dispatcher dynamically dispatches vehicles and drones to deliver the goods to customers before their delivery deadline. Vehicles can deliver multiple packages in one route but travel relatively slowly due to the urban traffic. Drones travel faster, but they have limited capacity and require charging or battery swaps. To exploit the different strengths of the fleets, we propose a deep Q-learning approach. Our method learns the value of assigning a new customer to either drones or vehicles as well as the option to not offer service at all. In a systematic computational analysis, we show the superiority of our policy compared to benchmark policies and the effectiveness of our deep Q-learning approach. We also show that the combination of state and action features is very valuable and that our policy can maintain effectiveness when demand data and the fleet size change moderately.}
}
@Article{Elvesier.com,
  title        = {Pattern Recognition},
  author       = {Elvesier},
  date         = {[Consultado el 2 de marzo de 2022].},
  journal      = {Author information pack},
  issn         = {0031-3203},
  url          = {https://www.elsevier.com/journals/pattern-recognition/0031-3203/guide-for-authors},
  year         = {2022}
}
@Article{Elvesier,
  title        = {International journal of production economics},
  author       = {Elvesier},
  date         = {[Consultado el 2 de marzo de 2022].},
  journal      = {Author information pack},
  url          = {https://www.sciencedirect.com/journal/international-journal-of-production-economics},
  year         = {2022}
}
@article{european,
title = {European Journal of Operational Research},
journal = {European Journal of Operational Research},
volume = {298},
number = {3},
pages = {939-952},
year = {2022},
doi = {https://doi.org/10.1016/j.ejor.2021.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0377221721005361},
author = {Elsevier},
keywords = {Transportation, Same-day delivery, Reinforcement learning, Dynamic vehicle routing}
}
